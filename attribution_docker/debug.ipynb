{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-08\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-09\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-10\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-11\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-12\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-13\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-14\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-15\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-16\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-08\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-09\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-10\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-11\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-12\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-13\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-14\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-15\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-16\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-08\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-09\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-10\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-11\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-12\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-13\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-14\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-15\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-16\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-08\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-09\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-10\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-11\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-12\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-13\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-14\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-15\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-16\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-08\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-09\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-10\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-11\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-12\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-13\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-14\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-15\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-16\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-08\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-09\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-10\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-11\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-12\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-13\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-14\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-15\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 2025-04-16\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-08: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-09: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-10: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-11: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-12: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-13: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-14: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-15: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-16: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-08: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-09: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-10: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-11: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-12: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-13: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-14: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-15: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-16: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n",
      "Fetching data for 2025-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-08: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-09: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-10: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-11: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-12: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-13: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-14: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-15: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for the date 2025-04-16: cumsum is not supported for object dtype\n",
      "Fetching data for 2025-04-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2309: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2323: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n",
      "/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/google/cloud/bigquery/table.py:2337: UserWarning: Unable to represent RANGE schema as struct using pandas ArrowDtype. Using `object` instead. To use ArrowDtype, use pandas >= 1.5 and pyarrow >= 10.0.1.\n",
      "  warnings.warn(_RANGE_PYARROW_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-04-17\n",
      "Fetching data for 2025-04-18\n",
      "No data for 2025-04-18\n",
      "Fetching data for 2025-04-19\n",
      "No data for 2025-04-19\n",
      "Fetching data for 2025-04-20\n",
      "No data for 2025-04-20\n",
      "Fetching data for 2025-04-21\n",
      "No data for 2025-04-21\n",
      "Fetching data for 2025-04-22\n",
      "No data for 2025-04-22\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'channels_agg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'channels_agg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1885\u001b[0m\n\u001b[1;32m   1882\u001b[0m user_dfs_regis \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_df_all_regis_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m suffixes]\n\u001b[1;32m   1883\u001b[0m user_df_all_regis \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(user_dfs_regis, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1885\u001b[0m user_df_all_regis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_touchpoints\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43muser_df_all_regis\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchannels_agg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1886\u001b[0m user_df_all_regis[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversion_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistration\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1887\u001b[0m markov_transition_matrix_all_regis[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversion_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistration\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/pandas/core/frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3458\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3460\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clean_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[1;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'channels_agg'"
     ]
    }
   ],
   "source": [
    "from marketing_attribution_models import MAM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from markovclick.models import MarkovClickstream\n",
    "from markovclick.viz import visualise_markov_chain\n",
    "import os\n",
    "import graphviz\n",
    "import matplotlib as mpl\n",
    "from pandas.io import gbq\n",
    "import pandas_gbq\n",
    "import glob\n",
    "from pylab import *\n",
    "import tempfile\n",
    "import json\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import re\n",
    "from google.cloud import bigquery\n",
    "\n",
    "################################################# Data Loading  #########################################\n",
    "\n",
    "project = \"ft-customer-analytics\"\n",
    "location = \"EU\"\n",
    "client = bigquery.Client(project=project, location=location)\n",
    "\n",
    "################################################# Define variables #################################################\n",
    "\n",
    "ids = \"user_guid\"\n",
    "date = \"attribution_visit_start_time\"\n",
    "touchpoint = \"touchpoint\"\n",
    "transaction = \"converting_visit\"\n",
    "\n",
    "################################################# Define the date range for processing #################################################\n",
    "\n",
    "end_date = pd.Timestamp.today().date() - pd.DateOffset(days=1)\n",
    "start_date = end_date - pd.DateOffset(days=14)\n",
    "\n",
    "start_date = start_date.date()\n",
    "end_date = end_date.date() \n",
    "\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_90_days_lookback_table\"\n",
    "\n",
    "################################################# Output DataFrames  #################################################\n",
    "\n",
    "attribution_df_all_subs_90 = pd.DataFrame()\n",
    "normalized_removal_effects_all_subs_90 = pd.DataFrame()\n",
    "markov_transition_matrix_all_subs_90 = pd.DataFrame()\n",
    "user_df_all_subs_90 = pd.DataFrame()\n",
    "conversion_window_df_subs = pd.DataFrame()\n",
    "\n",
    "################################################# Process Data for Each Day #########################################\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "\n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    sub_df = df[df[\"conversion_type\"] == \"Subscription\"].drop(columns=[\"conversion_type\"])\n",
    "\n",
    "    sub_df[\"user_max_date\"] = sub_df.groupby(ids)[\"conversion_visit_timestamp\"].transform(\"max\")\n",
    "    sub_df[transaction] = 0\n",
    "    sub_df.loc[(sub_df[date] == sub_df[\"user_max_date\"]) & (sub_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "\n",
    "    #sub_df.drop(columns=[\"user_max_date\"], inplace=True)\n",
    "    sub_df = sub_df.sort_values([ids, date], ascending=[False, True])\n",
    "\n",
    "    sub_df[\"run_date\"] = current_date.date()\n",
    "\n",
    "    ################################################# Median day calculation #########################################\n",
    "    \n",
    "    # Initialize a list to store each user's median time to subscribe\n",
    "    user_median_days = []\n",
    "\n",
    "    # Calculate the median days for each user\n",
    "    for user_guid, user_data in sub_df.groupby(ids):\n",
    "        # Find the earliest visit where transaction = 0 (initial visit)\n",
    "        first_visit = user_data[user_data[transaction] == 0][date].min()\n",
    "\n",
    "        # If no valid first visit is found, skip this user\n",
    "        if pd.isnull(first_visit):\n",
    "            continue\n",
    "\n",
    "        # Find the conversion date (transaction = 1)\n",
    "        conversion_date = user_data[user_data[transaction] == 1][date].min()\n",
    "\n",
    "        # Calculate the time difference in days\n",
    "        if pd.notnull(conversion_date):\n",
    "            days_to_convert = (conversion_date - first_visit).days\n",
    "            user_median_days.append(days_to_convert)\n",
    "\n",
    "    # Calculate the median of the user's conversion times\n",
    "    if user_median_days:\n",
    "        median_days_to_subscribe = pd.Series(user_median_days).median()\n",
    "    else:\n",
    "        median_days_to_subscribe = None  # If no data, set median as None\n",
    "\n",
    "    # Add the calculated median days and run date to the output DataFrame\n",
    "    conversion_window_df_subs = pd.concat(\n",
    "        [\n",
    "            conversion_window_df_subs,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"stage\": [\"subscriber\"],\n",
    "                    \"median_days\": [median_days_to_subscribe],\n",
    "                    \"run_date\": [current_date.date()],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    ################################################# MAM Initialization #########################################\n",
    "\n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            sub_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "\n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "\n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "\n",
    "        ################################################# Process Results #########################################\n",
    "\n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "\n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "\n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "\n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "\n",
    "        # Now concatenate user_df_temp into user_df_all_subs_90\n",
    "        user_df_all_subs_90 = pd.concat(\n",
    "            [user_df_all_subs_90, user_df_temp], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Proceed with processing markov_transition_matrix and other dataframes as before\n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_subs_90 = pd.concat(\n",
    "            [markov_transition_matrix_all_subs_90, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_subs_90 = pd.concat(\n",
    "            [normalized_removal_effects_all_subs_90, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_subs_90 = pd.concat(\n",
    "            [attribution_df_all_subs_90, attribution_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "attribution_df_all_subs_90[\"conversion_window\"] = 90\n",
    "normalized_removal_effects_all_subs_90[\"conversion_window\"] = 90\n",
    "markov_transition_matrix_all_subs_90[\"conversion_window\"] = 90\n",
    "user_df_all_subs_90[\"conversion_window\"] = 90\n",
    "\n",
    "attribution_df_all_subs_90[\"conversion_type\"] = \"Subscription\"\n",
    "normalized_removal_effects_all_subs_90[\"conversion_type\"] = \"Subscription\"\n",
    "markov_transition_matrix_all_subs_90[\"conversion_type\"] = \"Subscription\"\n",
    "user_df_all_subs_90[\"conversion_type\"] = \"Subscription\"\n",
    "\n",
    "################################################################################################## Sub 60 days ##########################################################################################\n",
    "\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_60_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_subs_60 = pd.DataFrame()\n",
    "normalized_removal_effects_all_subs_60 = pd.DataFrame()\n",
    "markov_transition_matrix_all_subs_60 = pd.DataFrame()\n",
    "user_df_all_subs_60 = pd.DataFrame()\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "    \n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    sub_df = df[df[\"conversion_type\"] == \"Subscription\"].drop(columns=[\"conversion_type\"])\n",
    "    \n",
    "    sub_df[\"user_max_date\"] = sub_df.groupby(ids)[date].transform(\"max\")\n",
    "    sub_df[transaction] = 0\n",
    "    sub_df.loc[(sub_df[date] == sub_df[\"user_max_date\"]) & (sub_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "    sub_df.drop(columns=[\"user_max_date\"], inplace=True)\n",
    "    sub_df = sub_df.sort_values([ids, date], ascending=[False, True])\n",
    "    \n",
    "    sub_df[\"run_date\"] = current_date.date()\n",
    "    \n",
    "    ################################################# MAM Initialization #########################################\n",
    "    \n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            sub_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "    \n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "    \n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "    \n",
    "        ################################################# Process Results #########################################\n",
    "    \n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "    \n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "    \n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "    \n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "    \n",
    "        # Now concatenate user_df_temp into user_df_all_subs_60\n",
    "        user_df_all_subs_60 = pd.concat(\n",
    "            [user_df_all_subs_60, user_df_temp], ignore_index=True\n",
    "        )\n",
    "    \n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_subs_60 = pd.concat(\n",
    "            [markov_transition_matrix_all_subs_60, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    \n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_subs_60 = pd.concat(\n",
    "            [normalized_removal_effects_all_subs_60, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    \n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_subs_60 = pd.concat(\n",
    "            [attribution_df_all_subs_60, attribution_df], ignore_index=True\n",
    "        )\n",
    "    \n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "# Update the conversion window to 60\n",
    "attribution_df_all_subs_60[\"conversion_window\"] = 60\n",
    "normalized_removal_effects_all_subs_60[\"conversion_window\"] = 60\n",
    "markov_transition_matrix_all_subs_60[\"conversion_window\"] = 60\n",
    "user_df_all_subs_60[\"conversion_window\"] = 60\n",
    "\n",
    "attribution_df_all_subs_60[\"conversion_type\"] = \"Subscription\"\n",
    "normalized_removal_effects_all_subs_60[\"conversion_type\"] = \"Subscription\"\n",
    "markov_transition_matrix_all_subs_60[\"conversion_type\"] = \"Subscription\"\n",
    "user_df_all_subs_60[\"conversion_type\"] = \"Subscription\"\n",
    "\n",
    "################################################################################################## Sub 30 days ##########################################################################################\n",
    "\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_30_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_subs_30 = pd.DataFrame()\n",
    "normalized_removal_effects_all_subs_30 = pd.DataFrame()\n",
    "markov_transition_matrix_all_subs_30 = pd.DataFrame()\n",
    "user_df_all_subs_30 = pd.DataFrame()\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "    \n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    sub_df = df[df[\"conversion_type\"] == \"Subscription\"].drop(columns=[\"conversion_type\"])\n",
    "    \n",
    "    sub_df[\"user_max_date\"] = sub_df.groupby(ids)[date].transform(\"max\")\n",
    "    sub_df[transaction] = 0\n",
    "    sub_df.loc[(sub_df[date] == sub_df[\"user_max_date\"]) & (sub_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "    sub_df.drop(columns=[\"user_max_date\"], inplace=True)\n",
    "    sub_df = sub_df.sort_values([ids, date], ascending=[False, True])\n",
    "    \n",
    "    sub_df[\"run_date\"] = current_date.date()\n",
    "    \n",
    "    ################################################# MAM Initialization #########################################\n",
    "    \n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            sub_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "    \n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "    \n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "    \n",
    "        ################################################# Process Results #########################################\n",
    "    \n",
    "       # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "    \n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "    \n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "    \n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "    \n",
    "        # Now concatenate user_df_temp into user_df_all_subs_30\n",
    "        user_df_all_subs_30 = pd.concat(\n",
    "            [user_df_all_subs_30, user_df_temp], ignore_index=True\n",
    "        )\n",
    "    \n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_subs_30 = pd.concat(\n",
    "            [markov_transition_matrix_all_subs_30, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    \n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_subs_30 = pd.concat(\n",
    "            [normalized_removal_effects_all_subs_30, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    \n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_subs_30 = pd.concat(\n",
    "            [attribution_df_all_subs_30, attribution_df], ignore_index=True\n",
    "        )\n",
    "    \n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "# Update the conversion window to 60\n",
    "attribution_df_all_subs_30[\"conversion_window\"] = 30\n",
    "normalized_removal_effects_all_subs_30[\"conversion_window\"] = 30\n",
    "markov_transition_matrix_all_subs_30[\"conversion_window\"] = 30\n",
    "user_df_all_subs_30[\"conversion_window\"] = 30\n",
    "\n",
    "attribution_df_all_subs_30[\"conversion_type\"] = \"Subscription\"\n",
    "normalized_removal_effects_all_subs_30[\"conversion_type\"] = \"Subscription\"\n",
    "markov_transition_matrix_all_subs_30[\"conversion_type\"] = \"Subscription\"\n",
    "user_df_all_subs_30[\"conversion_type\"] = \"Subscription\"\n",
    "\n",
    "############################################################################################## Merge subs ##########################################################################################\n",
    "suffixes = ['30', '60', '90']\n",
    "\n",
    "attribution_dfs = [globals()[f'attribution_df_all_subs_{suffix}'] for suffix in suffixes]\n",
    "attribution_df_all_subs = pd.concat(attribution_dfs, ignore_index=True)\n",
    "\n",
    "removal_effects_dfs = [globals()[f'normalized_removal_effects_all_subs_{suffix}'] for suffix in suffixes]\n",
    "normalized_removal_effects_all_subs = pd.concat(removal_effects_dfs, ignore_index=True)\n",
    "\n",
    "markov_transition_dfs = [globals()[f'markov_transition_matrix_all_subs_{suffix}'] for suffix in suffixes]\n",
    "markov_transition_matrix_all_subs = pd.concat(markov_transition_dfs, ignore_index=True)\n",
    "\n",
    "user_dfs = [globals()[f'user_df_all_subs_{suffix}'] for suffix in suffixes]\n",
    "user_df_all_subs = pd.concat(user_dfs, ignore_index=True)\n",
    "\n",
    "user_df_all_subs['num_touchpoints'] = user_df_all_subs['channels_agg'].str.split(' > ').apply(len)\n",
    "user_df_all_subs[\"conversion_type\"] = \"Subscription\"\n",
    "markov_transition_matrix_all_subs[\"conversion_type\"] = \"Subscription\"\n",
    "normalized_removal_effects_all_subs[\"conversion_type\"] = \"Subscription\"\n",
    "attribution_df_all_subs[\"conversion_type\"] = \"Subscription\"\n",
    "\n",
    "# del attribution_df_all_subs_30\n",
    "# del normalized_removal_effects_all_subs_30\n",
    "# del markov_transition_matrix_all_subs_30\n",
    "# del user_df_all_subs_30\n",
    "\n",
    "# del attribution_df_all_subs_60\n",
    "# del normalized_removal_effects_all_subs_60\n",
    "# del markov_transition_matrix_all_subs_60\n",
    "# del user_df_all_subs_60\n",
    "\n",
    "# del attribution_df_all_subs_90\n",
    "# del normalized_removal_effects_all_subs_90\n",
    "# del markov_transition_matrix_all_subs_90\n",
    "# del user_df_all_subs_90\n",
    "# gc.collect()\n",
    "\n",
    "\n",
    "############################################################################################## Trial 90 days ##########################################################################################\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_90_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_trial_90 = pd.DataFrame()\n",
    "normalized_removal_effects_all_trial_90 = pd.DataFrame()\n",
    "markov_transition_matrix_all_trial_90 = pd.DataFrame()\n",
    "user_df_all_trial_90 = pd.DataFrame()\n",
    "conversion_window_df_trial = pd.DataFrame()\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "    \n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    trial_df = df[df[\"conversion_type\"] == \"Trial\"].drop(columns=[\"conversion_type\"])\n",
    "\n",
    "    trial_df[\"user_max_date\"] = trial_df.groupby(ids)[date].transform(\"max\")\n",
    "    trial_df[transaction] = 0\n",
    "    trial_df.loc[(trial_df[date] == trial_df[\"user_max_date\"]) & (trial_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "    trial_df.drop(columns=[\"user_max_date\"], inplace=True)\n",
    "    trial_df = trial_df.sort_values([ids, date], ascending=[False, True])\n",
    "\n",
    "    trial_df[\"run_date\"] = current_date.date()\n",
    "\n",
    "    ################################################# Median day calculation #########################################\n",
    "    \n",
    "    # Initialize a list to store each user's median time to subscribe\n",
    "    user_median_days = []\n",
    "\n",
    "    # Calculate the median days for each user\n",
    "    for user_guid, user_data in trial_df.groupby(ids):\n",
    "        # Find the earliest visit where transaction = 0 (initial visit)\n",
    "        first_visit = user_data[user_data[transaction] == 0][date].min()\n",
    "\n",
    "        # If no valid first visit is found, skip this user\n",
    "        if pd.isnull(first_visit):\n",
    "            continue\n",
    "\n",
    "        # Find the conversion date (transaction = 1)\n",
    "        conversion_date = user_data[user_data[transaction] == 1][date].min()\n",
    "\n",
    "        # Calculate the time difference in days\n",
    "        if pd.notnull(conversion_date):\n",
    "            days_to_convert = (conversion_date - first_visit).days\n",
    "            user_median_days.append(days_to_convert)\n",
    "\n",
    "    # Calculate the median of the user's conversion times\n",
    "    if user_median_days:\n",
    "        median_days_to_subscribe = pd.Series(user_median_days).median()\n",
    "    else:\n",
    "        median_days_to_subscribe = None  # If no data, set median as None\n",
    "\n",
    "    # Add the calculated median days and run date to the output DataFrame\n",
    "    conversion_window_df_trial = pd.concat(\n",
    "        [\n",
    "            conversion_window_df_trial,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"stage\": [\"trial\"],\n",
    "                    \"median_days\": [median_days_to_subscribe],\n",
    "                    \"run_date\": [current_date.date()],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    \n",
    "    ################################################# MAM Initialization #########################################\n",
    "    \n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            trial_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "\n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "\n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "\n",
    "        ################################################# Process Results #########################################\n",
    "\n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "\n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "\n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "\n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "\n",
    "        # Now concatenate user_df_temp into user_df_all_trial_90\n",
    "        user_df_all_trial_90 = pd.concat(\n",
    "            [user_df_all_trial_90, user_df_temp], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_trial_90 = pd.concat(\n",
    "            [markov_transition_matrix_all_trial_90, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_trial_90 = pd.concat(\n",
    "            [normalized_removal_effects_all_trial_90, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_trial_90 = pd.concat(\n",
    "            [attribution_df_all_trial_90, attribution_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "attribution_df_all_trial_90[\"conversion_window\"] = 90\n",
    "normalized_removal_effects_all_trial_90[\"conversion_window\"] = 90\n",
    "markov_transition_matrix_all_trial_90[\"conversion_window\"] = 90\n",
    "user_df_all_trial_90[\"conversion_window\"] = 90\n",
    "\n",
    "attribution_df_all_trial_90[\"conversion_type\"] = \"Trial\"\n",
    "normalized_removal_effects_all_trial_90[\"conversion_type\"] = \"Trial\"\n",
    "markov_transition_matrix_all_trial_90[\"conversion_type\"] = \"Trial\"\n",
    "user_df_all_trial_90[\"conversion_type\"] = \"Trial\"\n",
    "\n",
    "############################################################################################## Trial 60 days ##########################################################################################\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_60_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_trial_60 = pd.DataFrame()\n",
    "normalized_removal_effects_all_trial_60 = pd.DataFrame()\n",
    "markov_transition_matrix_all_trial_60 = pd.DataFrame()\n",
    "user_df_all_trial_60 = pd.DataFrame()\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "    \n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    trial_df = df[df[\"conversion_type\"] == \"Trial\"].drop(columns=[\"conversion_type\"])\n",
    "\n",
    "    trial_df[\"user_max_date\"] = trial_df.groupby(ids)[date].transform(\"max\")\n",
    "    trial_df[transaction] = 0\n",
    "    trial_df.loc[(trial_df[date] == trial_df[\"user_max_date\"]) & (trial_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "    trial_df.drop(columns=[\"user_max_date\"], inplace=True)\n",
    "    trial_df = trial_df.sort_values([ids, date], ascending=[False, True])\n",
    "\n",
    "    trial_df[\"run_date\"] = current_date.date()\n",
    "    \n",
    "    ################################################# MAM Initialization #########################################\n",
    "    \n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            trial_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "\n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "\n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "\n",
    "        ################################################# Process Results #########################################\n",
    "\n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "\n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "\n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "\n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "\n",
    "        # Now concatenate user_df_temp into user_df_all_trial_60\n",
    "        user_df_all_trial_60 = pd.concat(\n",
    "            [user_df_all_trial_60, user_df_temp], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_trial_60 = pd.concat(\n",
    "            [markov_transition_matrix_all_trial_60, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_trial_60 = pd.concat(\n",
    "            [normalized_removal_effects_all_trial_60, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_trial_60 = pd.concat(\n",
    "            [attribution_df_all_trial_60, attribution_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "attribution_df_all_trial_60[\"conversion_window\"] = 60\n",
    "normalized_removal_effects_all_trial_60[\"conversion_window\"] = 60\n",
    "markov_transition_matrix_all_trial_60[\"conversion_window\"] = 60\n",
    "user_df_all_trial_60[\"conversion_window\"] = 60\n",
    "\n",
    "attribution_df_all_trial_60[\"conversion_type\"] = \"Trial\"\n",
    "normalized_removal_effects_all_trial_60[\"conversion_type\"] = \"Trial\"\n",
    "markov_transition_matrix_all_trial_60[\"conversion_type\"] = \"Trial\"\n",
    "user_df_all_trial_60[\"conversion_type\"] = \"Trial\"\n",
    "\n",
    "############################################################################################## Trial 30 days ##########################################################################################\n",
    "\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_30_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_trial_30 = pd.DataFrame()\n",
    "normalized_removal_effects_all_trial_30 = pd.DataFrame()\n",
    "markov_transition_matrix_all_trial_30 = pd.DataFrame()\n",
    "user_df_all_trial_30 = pd.DataFrame()\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "    \n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    trial_df = df[df[\"conversion_type\"] == \"Trial\"].drop(columns=[\"conversion_type\"])\n",
    "\n",
    "    trial_df[\"user_max_date\"] = trial_df.groupby(ids)[date].transform(\"max\")\n",
    "    trial_df[transaction] = 0\n",
    "    trial_df.loc[(trial_df[date] == trial_df[\"user_max_date\"]) & (trial_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "    trial_df.drop(columns=[\"user_max_date\"], inplace=True)\n",
    "    trial_df = trial_df.sort_values([ids, date], ascending=[False, True])\n",
    "\n",
    "    trial_df[\"run_date\"] = current_date.date()\n",
    "\n",
    "    ################################################# MAM Initialization #########################################\n",
    "    \n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            trial_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "\n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "\n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "\n",
    "        ################################################# Process Results #########################################\n",
    "\n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "\n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "\n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "\n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "\n",
    "        # Now concatenate user_df_temp into user_df_all_trial_30\n",
    "        user_df_all_trial_30 = pd.concat(\n",
    "            [user_df_all_trial_30, user_df_temp], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_trial_30 = pd.concat(\n",
    "            [markov_transition_matrix_all_trial_30, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_trial_30 = pd.concat(\n",
    "            [normalized_removal_effects_all_trial_30, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_trial_30 = pd.concat(\n",
    "            [attribution_df_all_trial_30, attribution_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "attribution_df_all_trial_30[\"conversion_window\"] = 30\n",
    "normalized_removal_effects_all_trial_30[\"conversion_window\"] = 30\n",
    "markov_transition_matrix_all_trial_30[\"conversion_window\"] = 30\n",
    "user_df_all_trial_30[\"conversion_window\"] = 30\n",
    "\n",
    "attribution_df_all_trial_30[\"conversion_type\"] = \"Trial\"\n",
    "normalized_removal_effects_all_trial_30[\"conversion_type\"] = \"Trial\"\n",
    "markov_transition_matrix_all_trial_30[\"conversion_type\"] = \"Trial\"\n",
    "user_df_all_trial_30[\"conversion_type\"] = \"Trial\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################## Merge trials ##########################################################################################\n",
    "suffixes = [\"30\", \"60\", \"90\"]\n",
    "\n",
    "attribution_dfs_trial = [\n",
    "    globals()[f\"attribution_df_all_trial_{suffix}\"] for suffix in suffixes\n",
    "]\n",
    "attribution_df_all_trial = pd.concat(attribution_dfs_trial, ignore_index=True)\n",
    "\n",
    "removal_effects_dfs_trial = [\n",
    "    globals()[f\"normalized_removal_effects_all_trial_{suffix}\"] for suffix in suffixes\n",
    "]\n",
    "normalized_removal_effects_all_trial = pd.concat(\n",
    "    removal_effects_dfs_trial, ignore_index=True\n",
    ")\n",
    "\n",
    "markov_transition_dfs_trial = [\n",
    "    globals()[f\"markov_transition_matrix_all_trial_{suffix}\"] for suffix in suffixes\n",
    "]\n",
    "markov_transition_matrix_all_trial = pd.concat(\n",
    "    markov_transition_dfs_trial, ignore_index=True\n",
    ")\n",
    "\n",
    "user_dfs_trial = [globals()[f\"user_df_all_trial_{suffix}\"] for suffix in suffixes]\n",
    "user_df_all_trial = pd.concat(user_dfs_trial, ignore_index=True)\n",
    "\n",
    "user_df_all_trial[\"num_touchpoints\"] = (\n",
    "    user_df_all_trial[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    ")\n",
    "user_df_all_trial[\"conversion_type\"] = \"Trial\"\n",
    "markov_transition_matrix_all_trial[\"conversion_type\"] = \"Trial\"\n",
    "normalized_removal_effects_all_trial[\"conversion_type\"] = \"Trial\"\n",
    "attribution_df_all_trial[\"conversion_type\"] = \"Trial\"\n",
    "\n",
    "############################################################################################## Regis 90 days ##########################################################################################\n",
    "\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_90_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_regis_90 = pd.DataFrame()\n",
    "normalized_removal_effects_all_regis_90 = pd.DataFrame()\n",
    "markov_transition_matrix_all_regis_90 = pd.DataFrame()\n",
    "user_df_all_regis_90 = pd.DataFrame()\n",
    "conversion_window_df_regis = pd.DataFrame()\n",
    "\n",
    "################################################# Process Data for Each Day #########################################\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "\n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    regis_df = df[df[\"conversion_type\"] == \"registration\"].drop(columns=[\"conversion_type\"])\n",
    "\n",
    "    regis_df[\"user_max_date\"] = regis_df.groupby(ids)[\"conversion_visit_timestamp\"].transform(\"max\")\n",
    "    regis_df[transaction] = 0\n",
    "    regis_df.loc[(regis_df[date] == regis_df[\"user_max_date\"]) & (regis_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "\n",
    "    regis_df = regis_df.sort_values([ids, date], ascending=[False, True])\n",
    "\n",
    "    regis_df[\"run_date\"] = current_date.date()\n",
    "\n",
    "    ################################################# Median day calculation #########################################\n",
    "    \n",
    "    # Initialize a list to store each user's median time to register\n",
    "    user_median_days = []\n",
    "\n",
    "    # Calculate the median days for each user\n",
    "    for user_guid, user_data in regis_df.groupby(ids):\n",
    "        # Find the earliest visit where transaction = 0 (initial visit)\n",
    "        first_visit = user_data[user_data[transaction] == 0][date].min()\n",
    "\n",
    "        # If no valid first visit is found, skip this user\n",
    "        if pd.isnull(first_visit):\n",
    "            continue\n",
    "\n",
    "        # Find the conversion date (transaction = 1)\n",
    "        conversion_date = user_data[user_data[transaction] == 1][date].min()\n",
    "\n",
    "        # Calculate the time difference in days\n",
    "        if pd.notnull(conversion_date):\n",
    "            days_to_convert = (conversion_date - first_visit).days\n",
    "            user_median_days.append(days_to_convert)\n",
    "\n",
    "    # Calculate the median of the user's conversion times\n",
    "    if user_median_days:\n",
    "        median_days_to_register = pd.Series(user_median_days).median()\n",
    "    else:\n",
    "        median_days_to_register = None  # If no data, set median as None\n",
    "\n",
    "    # Add the calculated median days and run date to the output DataFrame\n",
    "    conversion_window_df_regis = pd.concat(\n",
    "        [\n",
    "            conversion_window_df_regis,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"stage\": [\"registration\"],\n",
    "                    \"median_days\": [median_days_to_register],\n",
    "                    \"run_date\": [current_date.date()],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    ################################################# MAM Initialization #########################################\n",
    "\n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            regis_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "\n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "\n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "\n",
    "        ################################################# Process Results #########################################\n",
    "\n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "\n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "\n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "\n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "\n",
    "        # Now concatenate user_df_temp into user_df_all_regis_90\n",
    "        user_df_all_regis_90 = pd.concat(\n",
    "            [user_df_all_regis_90, user_df_temp], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Proceed with processing markov_transition_matrix and other dataframes as before\n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_regis_90 = pd.concat(\n",
    "            [markov_transition_matrix_all_regis_90, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_regis_90 = pd.concat(\n",
    "            [normalized_removal_effects_all_regis_90, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_regis_90 = pd.concat(\n",
    "            [attribution_df_all_regis_90, attribution_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "attribution_df_all_regis_90[\"conversion_window\"] = 90\n",
    "normalized_removal_effects_all_regis_90[\"conversion_window\"] = 90\n",
    "markov_transition_matrix_all_regis_90[\"conversion_window\"] = 90\n",
    "user_df_all_regis_90[\"conversion_window\"] = 90\n",
    "\n",
    "attribution_df_all_regis_90[\"conversion_type\"] = \"registration\"\n",
    "normalized_removal_effects_all_regis_90[\"conversion_type\"] = \"registration\"\n",
    "markov_transition_matrix_all_regis_90[\"conversion_type\"] = \"registration\"\n",
    "user_df_all_regis_90[\"conversion_type\"] = \"registration\"\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################## Regis 60 days ##########################################################################################\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_60_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_regis_60 = pd.DataFrame()\n",
    "normalized_removal_effects_all_regis_60 = pd.DataFrame()\n",
    "markov_transition_matrix_all_regis_60 = pd.DataFrame()\n",
    "user_df_all_regis_60 = pd.DataFrame()\n",
    "conversion_window_df_regis = pd.DataFrame()\n",
    "\n",
    "################################################# Process Data for Each Day #########################################\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "\n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    regis_df = df[df[\"conversion_type\"] == \"registration\"].drop(columns=[\"conversion_type\"])\n",
    "\n",
    "    regis_df[\"user_max_date\"] = regis_df.groupby(ids)[\"conversion_visit_timestamp\"].transform(\"max\")\n",
    "    regis_df[transaction] = 0\n",
    "    regis_df.loc[(regis_df[date] == regis_df[\"user_max_date\"]) & (regis_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "\n",
    "    regis_df = regis_df.sort_values([ids, date], ascending=[False, True])\n",
    "\n",
    "    regis_df[\"run_date\"] = current_date.date()\n",
    "\n",
    "    ################################################# Median day calculation #########################################\n",
    "    \n",
    "    # Initialize a list to store each user's median time to register\n",
    "    user_median_days = []\n",
    "\n",
    "    # Calculate the median days for each user\n",
    "    for user_guid, user_data in regis_df.groupby(ids):\n",
    "        # Find the earliest visit where transaction = 0 (initial visit)\n",
    "        first_visit = user_data[user_data[transaction] == 0][date].min()\n",
    "\n",
    "        # If no valid first visit is found, skip this user\n",
    "        if pd.isnull(first_visit):\n",
    "            continue\n",
    "\n",
    "        # Find the conversion date (transaction = 1)\n",
    "        conversion_date = user_data[user_data[transaction] == 1][date].min()\n",
    "\n",
    "        # Calculate the time difference in days\n",
    "        if pd.notnull(conversion_date):\n",
    "            days_to_convert = (conversion_date - first_visit).days\n",
    "            user_median_days.append(days_to_convert)\n",
    "\n",
    "    # Calculate the median of the user's conversion times\n",
    "    if user_median_days:\n",
    "        median_days_to_register = pd.Series(user_median_days).median()\n",
    "    else:\n",
    "        median_days_to_register = None  # If no data, set median as None\n",
    "\n",
    "    # Add the calculated median days and run date to the output DataFrame\n",
    "    conversion_window_df_regis = pd.concat(\n",
    "        [\n",
    "            conversion_window_df_regis,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"stage\": [\"registration\"],\n",
    "                    \"median_days\": [median_days_to_register],\n",
    "                    \"run_date\": [current_date.date()],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    ################################################# MAM Initialization #########################################\n",
    "\n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            regis_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "\n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "\n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "\n",
    "        ################################################# Process Results #########################################\n",
    "\n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "\n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "\n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "\n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "\n",
    "        # Now concatenate user_df_temp into user_df_all_regis_60\n",
    "        user_df_all_regis_60 = pd.concat(\n",
    "            [user_df_all_regis_60, user_df_temp], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Proceed with processing markov_transition_matrix and other dataframes as before\n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_regis_60 = pd.concat(\n",
    "            [markov_transition_matrix_all_regis_60, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_regis_60 = pd.concat(\n",
    "            [normalized_removal_effects_all_regis_60, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_regis_60 = pd.concat(\n",
    "            [attribution_df_all_regis_60, attribution_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "attribution_df_all_regis_60[\"conversion_window\"] = 60\n",
    "normalized_removal_effects_all_regis_60[\"conversion_window\"] = 60\n",
    "markov_transition_matrix_all_regis_60[\"conversion_window\"] = 60\n",
    "user_df_all_regis_60[\"conversion_window\"] = 60\n",
    "\n",
    "attribution_df_all_regis_60[\"conversion_type\"] = \"registration\"\n",
    "normalized_removal_effects_all_regis_60[\"conversion_type\"] = \"registration\"\n",
    "markov_transition_matrix_all_regis_60[\"conversion_type\"] = \"registration\"\n",
    "user_df_all_regis_60[\"conversion_type\"] = \"registration\"\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################## Regis 30 days ##########################################################################################\n",
    "table_id = \"ft-customer-analytics.crg_nniu_attribution.stg_conversion_users_last_15_days_30_days_lookback_table\"\n",
    "\n",
    "attribution_df_all_regis_30 = pd.DataFrame()\n",
    "normalized_removal_effects_all_regis_30 = pd.DataFrame()\n",
    "markov_transition_matrix_all_regis_30 = pd.DataFrame()\n",
    "user_df_all_regis_30 = pd.DataFrame()\n",
    "conversion_window_df_regis = pd.DataFrame()\n",
    "\n",
    "################################################# Process Data for Each Day #########################################\n",
    "\n",
    "for current_date in pd.date_range(start_date, end_date, freq=\"D\"):\n",
    "    # Create SQL query for the current date\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM {table_id}\n",
    "    WHERE DATE(conversion_visit_timestamp) = \"{current_date.strftime('%Y-%m-%d')}\"\n",
    "    \"\"\"\n",
    "    print(f\"Fetching data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.to_dataframe()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        continue\n",
    "\n",
    "    ################################################# Data Cleaning  #########################################\n",
    "    \n",
    "    df[\"original_transaction\"] = df[\"converting_visit\"]\n",
    "    regis_df = df[df[\"conversion_type\"] == \"registration\"].drop(columns=[\"conversion_type\"])\n",
    "\n",
    "    regis_df[\"user_max_date\"] = regis_df.groupby(ids)[\"conversion_visit_timestamp\"].transform(\"max\")\n",
    "    regis_df[transaction] = 0\n",
    "    regis_df.loc[(regis_df[date] == regis_df[\"user_max_date\"]) & (regis_df[\"original_transaction\"] == 1), transaction] = 1\n",
    "\n",
    "    regis_df = regis_df.sort_values([ids, date], ascending=[False, True])\n",
    "\n",
    "    regis_df[\"run_date\"] = current_date.date()\n",
    "\n",
    "    ################################################# Median day calculation #########################################\n",
    "    \n",
    "    # Initialize a list to store each user's median time to register\n",
    "    user_median_days = []\n",
    "\n",
    "    # Calculate the median days for each user\n",
    "    for user_guid, user_data in regis_df.groupby(ids):\n",
    "        # Find the earliest visit where transaction = 0 (initial visit)\n",
    "        first_visit = user_data[user_data[transaction] == 0][date].min()\n",
    "\n",
    "        # If no valid first visit is found, skip this user\n",
    "        if pd.isnull(first_visit):\n",
    "            continue\n",
    "\n",
    "        # Find the conversion date (transaction = 1)\n",
    "        conversion_date = user_data[user_data[transaction] == 1][date].min()\n",
    "\n",
    "        # Calculate the time difference in days\n",
    "        if pd.notnull(conversion_date):\n",
    "            days_to_convert = (conversion_date - first_visit).days\n",
    "            user_median_days.append(days_to_convert)\n",
    "\n",
    "    # Calculate the median of the user's conversion times\n",
    "    if user_median_days:\n",
    "        median_days_to_register = pd.Series(user_median_days).median()\n",
    "    else:\n",
    "        median_days_to_register = None  # If no data, set median as None\n",
    "\n",
    "    # Add the calculated median days and run date to the output DataFrame\n",
    "    conversion_window_df_regis = pd.concat(\n",
    "        [\n",
    "            conversion_window_df_regis,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"stage\": [\"registration\"],\n",
    "                    \"median_days\": [median_days_to_register],\n",
    "                    \"run_date\": [current_date.date()],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    ################################################# MAM Initialization #########################################\n",
    "\n",
    "    try:\n",
    "        # Initialize the MAM class\n",
    "        attributions = MAM(\n",
    "            regis_df,\n",
    "            group_channels=True,\n",
    "            channels_colname=touchpoint,\n",
    "            journey_with_conv_colname=transaction,\n",
    "            group_channels_by_id_list=[ids],\n",
    "            group_timestamp_colname=date,\n",
    "            create_journey_id_based_on_conversion=True,\n",
    "        )\n",
    "\n",
    "        ################################################# Apply Attribution Models #########################################\n",
    "\n",
    "        attributions.attribution_last_click()\n",
    "        attributions.attribution_first_click()\n",
    "        attributions.attribution_position_based(\n",
    "            list_positions_first_middle_last=[0.3, 0.3, 0.4]\n",
    "        )\n",
    "        attributions.attribution_time_decay(\n",
    "            decay_over_time=0.6, frequency=7\n",
    "        )  # Frequency in hours\n",
    "        attribution_markov = attributions.attribution_markov(\n",
    "            transition_to_same_state=False\n",
    "        )\n",
    "\n",
    "        ################################################# Process Results #########################################\n",
    "\n",
    "        # User-level attribution data\n",
    "        user_df_temp = attributions.as_pd_dataframe()\n",
    "        user_df_temp[\"num_touchpoints\"] = (\n",
    "            user_df_temp[\"channels_agg\"].str.split(\" > \").apply(len)\n",
    "        )\n",
    "        user_df_temp[\"run_date\"] = current_date.date()\n",
    "\n",
    "        # Extract user_guid from journey_id\n",
    "        user_df_temp['user_guid'] = user_df_temp['journey_id'].str.extract(r'id:(.*)_J:0')[0]\n",
    "\n",
    "        # Prepare df for merging\n",
    "        df['conversion_visit_timestamp_date'] = df['conversion_visit_timestamp'].dt.date\n",
    "        product_arrangement_df = df[['user_guid', 'conversion_visit_timestamp_date', 'product_arrangement_id']].drop_duplicates()\n",
    "\n",
    "        # Merge user_df_temp with product_arrangement_df\n",
    "        user_df_temp = user_df_temp.merge(\n",
    "            product_arrangement_df,\n",
    "            left_on=['user_guid', 'run_date'],\n",
    "            right_on=['user_guid', 'conversion_visit_timestamp_date'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop 'conversion_visit_timestamp_date' column after merge\n",
    "        user_df_temp.drop(columns=['conversion_visit_timestamp_date'], inplace=True)\n",
    "\n",
    "        # Now concatenate user_df_temp into user_df_all_regis_30\n",
    "        user_df_all_regis_30 = pd.concat(\n",
    "            [user_df_all_regis_30, user_df_temp], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Proceed with processing markov_transition_matrix and other dataframes as before\n",
    "        # Markov transition matrix\n",
    "        markov_transition_matrix = attribution_markov[2].round(3)\n",
    "        markov_transition_matrix = markov_transition_matrix.rename(\n",
    "            index=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "            columns=lambda x: x.replace(\"(inicio)\", \"(start)\"),\n",
    "        )\n",
    "        markov_transition_matrix.reset_index(inplace=True)\n",
    "        markov_transition_matrix = pd.melt(\n",
    "            markov_transition_matrix,\n",
    "            id_vars=\"index\",\n",
    "            var_name=\"destination\",\n",
    "            value_name=\"probability\",\n",
    "        )\n",
    "        markov_transition_matrix.columns = [\"source\", \"destination\", \"probability\"]\n",
    "        markov_transition_matrix[\"run_date\"] = current_date.date()\n",
    "        markov_transition_matrix_all_regis_30 = pd.concat(\n",
    "            [markov_transition_matrix_all_regis_30, markov_transition_matrix],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Removal effects\n",
    "        removal_effect_matrix = attribution_markov[3].round(3)\n",
    "        channels = removal_effect_matrix.index\n",
    "        removal_effect_values = removal_effect_matrix[[\"removal_effect\"]]\n",
    "        normalized_values = (removal_effect_values / removal_effect_values.sum()) * 100\n",
    "        normalized_removal_effects = pd.DataFrame(\n",
    "            normalized_values, index=channels, columns=[\"removal_effect\"]\n",
    "        )\n",
    "        normalized_removal_effects[\"run_date\"] = current_date.date()\n",
    "        normalized_removal_effects[\"removal_effect_raw\"] = (\n",
    "            removal_effect_values.values.flatten()\n",
    "        )\n",
    "        normalized_removal_effects.reset_index(inplace=True)\n",
    "        normalized_removal_effects.rename(columns={\"index\": \"channel\"}, inplace=True)\n",
    "        normalized_removal_effects_all_regis_30 = pd.concat(\n",
    "            [normalized_removal_effects_all_regis_30, normalized_removal_effects],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Attribution by channels and models\n",
    "        attribution_df = attributions.group_by_channels_models\n",
    "        attribution_df[\"run_date\"] = current_date.date()\n",
    "        attribution_df.columns = attribution_df.columns.str.replace(\n",
    "            \".\", \"_\", regex=False\n",
    "        ).str.replace(\" \", \"_\", regex=False)\n",
    "        attribution_df_all_regis_30 = pd.concat(\n",
    "            [attribution_df_all_regis_30, attribution_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(f\"Processed data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"An error occurred for the date {current_date.strftime('%Y-%m-%d')}: {e}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "################################################# Finalize Results #########################################\n",
    "\n",
    "attribution_df_all_regis_30[\"conversion_window\"] = 30\n",
    "normalized_removal_effects_all_regis_30[\"conversion_window\"] = 30\n",
    "markov_transition_matrix_all_regis_30[\"conversion_window\"] = 30\n",
    "user_df_all_regis_30[\"conversion_window\"] = 30\n",
    "\n",
    "attribution_df_all_regis_30[\"conversion_type\"] = \"registration\"\n",
    "normalized_removal_effects_all_regis_30[\"conversion_type\"] = \"registration\"\n",
    "markov_transition_matrix_all_regis_30[\"conversion_type\"] = \"registration\"\n",
    "user_df_all_regis_30[\"conversion_type\"] = \"registration\"\n",
    "\n",
    "############################################################################################## Merge Regis ##########################################################################################\n",
    "suffixes = ['30', '60', '90']\n",
    "\n",
    "attribution_dfs_regis = [globals()[f'attribution_df_all_regis_{suffix}'] for suffix in suffixes]\n",
    "attribution_df_all_regis = pd.concat(attribution_dfs_regis, ignore_index=True)\n",
    "\n",
    "removal_effects_dfs_regis = [globals()[f'normalized_removal_effects_all_regis_{suffix}'] for suffix in suffixes]\n",
    "normalized_removal_effects_all_regis = pd.concat(removal_effects_dfs_regis, ignore_index=True)\n",
    "\n",
    "markov_transition_dfs_regis = [globals()[f'markov_transition_matrix_all_regis_{suffix}'] for suffix in suffixes]\n",
    "markov_transition_matrix_all_regis = pd.concat(markov_transition_dfs_regis, ignore_index=True)\n",
    "\n",
    "user_dfs_regis = [globals()[f'user_df_all_regis_{suffix}'] for suffix in suffixes]\n",
    "user_df_all_regis = pd.concat(user_dfs_regis, ignore_index=True)\n",
    "\n",
    "user_df_all_regis['num_touchpoints'] = user_df_all_regis['channels_agg'].str.split(' > ').apply(len)\n",
    "user_df_all_regis[\"conversion_type\"] = \"Registration\"\n",
    "markov_transition_matrix_all_regis[\"conversion_type\"] = \"Registration\"\n",
    "normalized_removal_effects_all_regis[\"conversion_type\"] = \"Registration\"\n",
    "attribution_df_all_regis[\"conversion_type\"] = \"Registration\"\n",
    "\n",
    "\n",
    "\n",
    "################################################# Merge Trial, Subscription, Registration subsets #########################################\n",
    "\n",
    "user_df_all = pd.concat([user_df_all_trial, user_df_all_subs], ignore_index=True)\n",
    "user_df_all= pd.concat([user_df_all, user_df_all_regis], ignore_index=True)\n",
    "\n",
    "markov_transition_matrix_all = pd.concat(\n",
    "    [markov_transition_matrix_all_trial, markov_transition_matrix_all_subs],\n",
    "    ignore_index=True,\n",
    ")\n",
    "markov_transition_matrix_all = pd.concat([markov_transition_matrix_all, markov_transition_matrix_all_regis], ignore_index=True)\n",
    "\n",
    "normalized_removal_effects_all = pd.concat(\n",
    "    [normalized_removal_effects_all_trial, normalized_removal_effects_all_subs],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "normalized_removal_effects_all = pd.concat([normalized_removal_effects_all, normalized_removal_effects_all_regis], ignore_index=True)\n",
    "\n",
    "attribution_df_all = pd.concat(\n",
    "    [attribution_df_all_subs, attribution_df_all_trial], ignore_index=True\n",
    ")\n",
    "\n",
    "attribution_df_all = pd.concat([attribution_df_all, attribution_df_all_regis], ignore_index=True)\n",
    "\n",
    "conversion_window_df = pd.concat(\n",
    "    [conversion_window_df_subs, conversion_window_df_trial], ignore_index=True\n",
    ")\n",
    "\n",
    "conversion_window_df = pd.concat(\n",
    "    [conversion_window_df, conversion_window_df_regis], ignore_index=True\n",
    ")\n",
    "\n",
    "# Rename user_df_all columns in big query format\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove patterns like '_0.3', '0.6', etc.\n",
    "    sanitized = re.sub(r\"(_)?\\d+\\.\\d+\", \"\", col_name)\n",
    "    # Replace multiple underscores with a single underscore\n",
    "    sanitized = re.sub(r\"_+\", \"_\", sanitized)\n",
    "    # Remove leading or trailing underscores\n",
    "    sanitized = sanitized.strip(\"_\")\n",
    "    return sanitized\n",
    "\n",
    "\n",
    "# Create a mapping from original to sanitized column names\n",
    "renamed_columns = {col: sanitize_column_name(col) for col in user_df_all.columns}\n",
    "\n",
    "# Rename the DataFrame columns\n",
    "user_df_all = user_df_all.rename(columns=renamed_columns)\n",
    "\n",
    "######################################################################################## Merge with LTV #####################################################################################\n",
    "\n",
    "client = bigquery.Client(project=\"ft-customer-analytics\")\n",
    "ltv_table_id = \"ft-customer-analytics.crg_nniu.ltv_last_15_days\"\n",
    "query = f\"\"\"\n",
    "    SELECT * FROM\n",
    "        {ltv_table_id}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "query_job = client.query(query)\n",
    "ltv_df = query_job.to_dataframe()\n",
    "\n",
    "ltv_df = ltv_df.dropna(subset=[\"ltv_acquisition_capped_12m\"])\n",
    "\n",
    "group_columns = [col for col in ltv_df.columns if col != \"ltv_acquisition_capped_12m\"]\n",
    "\n",
    "# Group by all columns except 'ltv_acquisition_capped_12m' and calculate its mean\n",
    "ltv_df = ltv_df.groupby(group_columns, as_index=False).agg(\n",
    "    ltv_acquisition_capped_12m=(\"ltv_acquisition_capped_12m\", \"mean\")\n",
    ")\n",
    "\n",
    "# # extract user guid from journey id\n",
    "user_df_all[\"user_guid\"] = user_df_all[\"journey_id\"].str.extract(r\"id:(.*)_J:0\")[0]\n",
    "\n",
    "# date column conversion for ltv df\n",
    "ltv_df[\"product_order_timestamp\"] = pd.to_datetime(\n",
    "    ltv_df[\"product_order_timestamp\"], utc=True\n",
    ")\n",
    "user_df_all[\"run_date\"] = pd.to_datetime(user_df_all[\"run_date\"], utc=True)\n",
    "\n",
    "# Convert date columns\n",
    "ltv_df[\"product_order_timestamp\"] = ltv_df[\"product_order_timestamp\"].dt.date\n",
    "user_df_all[\"run_date\"] = user_df_all[\"run_date\"].dt.date\n",
    "\n",
    "# convert ltv 12m as float\n",
    "ltv_df[\"ltv_acquisition_capped_12m\"] = ltv_df[\"ltv_acquisition_capped_12m\"].astype(\n",
    "    float\n",
    ")\n",
    "\n",
    "user_df_all = user_df_all[user_df_all[\"conversion_value\"] == 1]\n",
    "user_df_all[\"product_arrangement_id\"] = user_df_all[\"product_arrangement_id\"].fillna(0)\n",
    "\n",
    "user_df_all = pd.merge(\n",
    "    user_df_all,\n",
    "    ltv_df,\n",
    "    left_on=[\"product_arrangement_id\", \"run_date\"],\n",
    "    right_on=[\"product_arrangement_id\", \"product_order_timestamp\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Trial conversion window DataFrames\n",
    "user_df_trial_30 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 30)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Trial\")\n",
    "]\n",
    "user_df_trial_60 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 60)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Trial\")\n",
    "]\n",
    "user_df_trial_90 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 90)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Trial\")\n",
    "]\n",
    "\n",
    "# Subscription conversion window DataFrames\n",
    "user_df_subscription_30 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 30)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Subscription\")\n",
    "]\n",
    "user_df_subscription_60 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 60)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Subscription\")\n",
    "]\n",
    "user_df_subscription_90 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 90)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Subscription\")\n",
    "]\n",
    "\n",
    "#Registration conversion window DataFrames\n",
    "user_df_registration_30 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 30)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Registration\")\n",
    "]\n",
    "user_df_registration_60 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 60)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Registration\")\n",
    "]\n",
    "user_df_registration_90 = user_df_all[\n",
    "    (user_df_all[\"conversion_window\"] == 90)\n",
    "    & (user_df_all[\"conversion_type\"] == \"Registration\")\n",
    "]\n",
    "\n",
    "\n",
    "def calculate_removal_effect(row):\n",
    "    attr = row[\"attribution_markov_algorithmic\"]\n",
    "    ltv = row[\"ltv_acquisition_capped_12m\"]\n",
    "    channels = row[\"channels_agg\"]\n",
    "\n",
    "    if pd.isna(attr) or pd.isna(channels):\n",
    "        return np.nan\n",
    "\n",
    "    attr_parts = attr.split(\">\")\n",
    "    channel_parts = channels.split(\">\")\n",
    "\n",
    "    if len(attr_parts) != len(channel_parts):\n",
    "        return np.nan\n",
    "\n",
    "    new_parts = []\n",
    "    for channel, part in zip(channel_parts, attr_parts):\n",
    "        channel = channel.strip()\n",
    "        part = part.strip()\n",
    "        try:\n",
    "            val = float(part)\n",
    "            multiplied_val = val * ltv\n",
    "            formatted_val = f\"{multiplied_val}\"\n",
    "            new_parts.append(f\"{channel}: {formatted_val}\")\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    return \" > \".join(new_parts)\n",
    "\n",
    "\n",
    "def process_user_df(user_df):\n",
    "    # Apply the function to create the 'removal_effect_ltv' column\n",
    "    user_df[\"removal_effect_ltv\"] = user_df.apply(calculate_removal_effect, axis=1)\n",
    "    user_df = user_df.dropna(subset=[\"removal_effect_ltv\"]).copy()\n",
    "\n",
    "    # Split 'removal_effect_ltv' into a list of 'channel: ltv' strings\n",
    "    user_df[\"channel_ltv_list\"] = user_df[\"removal_effect_ltv\"].str.split(\" > \")\n",
    "\n",
    "    # Explode the list to have one 'channel: ltv' per row\n",
    "    df_exploded = user_df.explode(\"channel_ltv_list\")\n",
    "\n",
    "    # Split each 'channel_ltv' into 'channel' and 'ltv'\n",
    "    df_exploded[[\"channel\", \"ltv\"]] = df_exploded[\"channel_ltv_list\"].str.split(\n",
    "        \": \", n=1, expand=True\n",
    "    )\n",
    "\n",
    "    # Convert 'ltv' to numeric, handling any non-numeric values gracefully\n",
    "    df_exploded[\"ltv\"] = pd.to_numeric(df_exploded[\"ltv\"], errors=\"coerce\")\n",
    "\n",
    "    # Group by 'channel' and 'run_date', then calculate the mean LTV\n",
    "    average_ltv_per_channel = (\n",
    "        df_exploded.groupby([\"channel\", \"run_date\"])[\"ltv\"].mean().reset_index()\n",
    "    )\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    average_ltv_per_channel.rename(columns={\"ltv\": \"average_ltv\"}, inplace=True)\n",
    "\n",
    "    return average_ltv_per_channel\n",
    "\n",
    "\n",
    "# Applying the process to each DataFrame and storing the results\n",
    "user_df_trial_30_avg = process_user_df(user_df_trial_30)\n",
    "user_df_trial_60_avg = process_user_df(user_df_trial_60)\n",
    "user_df_trial_90_avg = process_user_df(user_df_trial_90)\n",
    "\n",
    "user_df_subscription_30_avg = process_user_df(user_df_subscription_30)\n",
    "user_df_subscription_60_avg = process_user_df(user_df_subscription_60)\n",
    "user_df_subscription_90_avg = process_user_df(user_df_subscription_90)\n",
    "\n",
    "user_df_registration_30_avg = process_user_df(user_df_registration_30)\n",
    "user_df_registration_60_avg = process_user_df(user_df_registration_60)\n",
    "user_df_registration_90_avg = process_user_df(user_df_registration_90)\n",
    "\n",
    "# Adding the 'conversion_window' and 'conversion_type' columns to each DataFrame\n",
    "user_df_trial_30_avg[\"conversion_window\"] = 30\n",
    "user_df_trial_30_avg[\"conversion_type\"] = \"Trial\"\n",
    "\n",
    "user_df_trial_60_avg[\"conversion_window\"] = 60\n",
    "user_df_trial_60_avg[\"conversion_type\"] = \"Trial\"\n",
    "\n",
    "user_df_trial_90_avg[\"conversion_window\"] = 90\n",
    "user_df_trial_90_avg[\"conversion_type\"] = \"Trial\"\n",
    "\n",
    "user_df_subscription_30_avg[\"conversion_window\"] = 30\n",
    "user_df_subscription_30_avg[\"conversion_type\"] = \"Subscription\"\n",
    "\n",
    "user_df_subscription_60_avg[\"conversion_window\"] = 60\n",
    "user_df_subscription_60_avg[\"conversion_type\"] = \"Subscription\"\n",
    "\n",
    "user_df_subscription_90_avg[\"conversion_window\"] = 90\n",
    "user_df_subscription_90_avg[\"conversion_type\"] = \"Subscription\"\n",
    "\n",
    "user_df_registration_30_avg['conversion_window'] = 30\n",
    "user_df_registration_30_avg['conversion_type'] = 'Registration'\n",
    "\n",
    "user_df_registration_60_avg['conversion_window'] = 60\n",
    "user_df_registration_60_avg['conversion_type'] = 'Registration'\n",
    "\n",
    "user_df_registration_90_avg['conversion_window'] = 90\n",
    "user_df_registration_90_avg['conversion_type'] = 'Registration'\n",
    "\n",
    "# Merging all DataFrames together\n",
    "average_ltv_per_channel = pd.concat(\n",
    "    [\n",
    "        user_df_trial_30_avg,\n",
    "        user_df_trial_60_avg,\n",
    "        user_df_trial_90_avg,\n",
    "        user_df_subscription_30_avg,\n",
    "        user_df_subscription_60_avg,\n",
    "        user_df_subscription_90_avg,\n",
    "        user_df_registration_30_avg,\n",
    "        user_df_registration_60_avg,\n",
    "        user_df_registration_90_avg\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "normalized_removal_effects_all = normalized_removal_effects_all[\n",
    "    normalized_removal_effects_all[\"removal_effect\"] != 0\n",
    "]\n",
    "normalized_removal_effects_all = pd.merge(\n",
    "    normalized_removal_effects_all,\n",
    "    average_ltv_per_channel,\n",
    "    left_on=(\"channel\", \"conversion_window\", \"conversion_type\", \"run_date\"),\n",
    "    right_on=(\"channel\", \"conversion_window\", \"conversion_type\", \"run_date\"),\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "user_df_all.drop(columns=[\"user_guid_x\", \"user_guid_y\"], inplace=True)\n",
    "\n",
    "######################################################################################## Data upload #####################################################################################\n",
    "\n",
    "#Configure the load job\n",
    "\n",
    "# job_config = bigquery.LoadJobConfig(\n",
    "#     write_disposition=bigquery.WriteDisposition.WRITE_APPEND,  # WRITE_TRUNCATE. # WRITE_APPEND\n",
    "#     source_format=bigquery.SourceFormat.PARQUET,\n",
    "#     autodetect=True,\n",
    "#     time_partitioning=bigquery.TimePartitioning(\n",
    "#         type_=bigquery.TimePartitioningType.DAY, field=\"run_date\"\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# dataframes = {\n",
    "#     \"ft-customer-analytics.crg_nniu.attribution_markov_transition_matrix_all\": markov_transition_matrix_all,\n",
    "#     \"ft-customer-analytics.crg_nniu.attribution_normalized_removal_effects_all\": normalized_removal_effects_all,\n",
    "#     \"ft-customer-analytics.crg_nniu.attribution_user_df_all\": user_df_all,\n",
    "#     \"ft-customer-analytics.crg_nniu.attribution_df_all\": attribution_df_all,\n",
    "#     \"ft-customer-analytics.crg_nniu.attribution_conversion_window_df\": conversion_window_df\n",
    "    \n",
    "# }\n",
    "\n",
    "# for destination_table, dataframe in dataframes.items():\n",
    "#     try:\n",
    "#         load_job = client.load_table_from_dataframe(\n",
    "#             dataframe.reset_index(drop=True), destination_table, job_config=job_config\n",
    "#         )\n",
    "#         load_job.result()\n",
    "#         print(f\"Load job for {destination_table} completed successfully.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading data to {destination_table}: {e}\")\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,  # Append after deleting old partitions\n",
    "    source_format=bigquery.SourceFormat.PARQUET,\n",
    "    autodetect=True,\n",
    "    time_partitioning=bigquery.TimePartitioning(\n",
    "        type_=bigquery.TimePartitioningType.DAY, field=\"run_date\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataframes = {\n",
    "    \"ft-customer-analytics.crg_nniu_attribution.attribution_markov_transition_matrix_all\": markov_transition_matrix_all,\n",
    "    \"ft-customer-analytics.crg_nniu_attribution.attribution_normalized_removal_effects_all\": normalized_removal_effects_all,\n",
    "    \"ft-customer-analytics.crg_nniu_attribution.attribution_user_df_all\": user_df_all,\n",
    "    \"ft-customer-analytics.crg_nniu_attribution.attribution_df_all\": attribution_df_all,\n",
    "    \"ft-customer-analytics.crg_nniu_attribution.attribution_conversion_window_df\": conversion_window_df\n",
    "}\n",
    "\n",
    "for destination_table, dataframe in dataframes.items():\n",
    "    # Extract unique run_dates from the DataFrame\n",
    "    run_dates = dataframe['run_date'].unique()  # Already in \"YYYY-MM-DD\" format\n",
    "    \n",
    "    # Delete existing data for these run_dates\n",
    "    for run_date in run_dates:\n",
    "        query = f\"\"\"\n",
    "            DELETE FROM `{destination_table}`\n",
    "            WHERE run_date = DATE('{run_date}')\n",
    "        \"\"\"\n",
    "        try:\n",
    "            delete_job = client.query(query)\n",
    "            delete_job.result()  # Wait for completion\n",
    "            print(f\"Deleted partition {run_date} from {destination_table}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting partition {run_date}: {e}\")\n",
    "    \n",
    "    # Load new data into the cleared partitions\n",
    "    try:\n",
    "        load_job = client.load_table_from_dataframe(\n",
    "            dataframe.reset_index(drop=True), destination_table, job_config=job_config\n",
    "        )\n",
    "        load_job.result()\n",
    "        print(f\"Loaded new data into {destination_table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data to {destination_table}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
